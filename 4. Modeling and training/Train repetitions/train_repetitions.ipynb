{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoSLkIhOATiN",
    "outputId": "da864866-fcf3-4a0d-a902-a8e7c4746c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WV9XpKDtAhnJ",
    "outputId": "e5640de9-fa42-4782-d6fc-b759b0eb0f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-33ffad38bb4e>:16: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Permute, Reshape\n",
    "from keras.layers import Bidirectional, LSTM, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dropout, Flatten, Lambda, Concatenate, BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import json\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "57I0_rSXAtqt",
    "outputId": "1f95d84e-58b7-4887-d5cf-58262b765ae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: {'shot': 0, 'sprint': 1, 'jump': 2, 'jog': 3, 'pass': 4}\n",
      "\n",
      "Order of sensors: ['leftShankAccX' 'leftShankAccY' 'leftShankAccZ' 'leftShankGyroX'\n",
      " 'leftShankGyroY' 'leftShankGyroZ' 'rightShankAccX' 'rightShankAccY'\n",
      " 'rightShankAccZ' 'rightShankGyroX' 'rightShankGyroY' 'rightShankGyroZ'\n",
      " 'leftThighAccX' 'leftThighAccY' 'leftThighAccZ' 'leftThighGyroX'\n",
      " 'leftThighGyroY' 'leftThighGyroZ' 'rightThighAccX' 'rightThighAccY'\n",
      " 'rightThighAccZ' 'rightThighGyroX' 'rightThighGyroY' 'rightThighGyroZ'\n",
      " 'pelvisAccX' 'pelvisAccY' 'pelvisAccZ' 'pelvisGyroX' 'pelvisGyroY'\n",
      " 'pelvisGyroZ']\n",
      "\n",
      "Size of dataset: (1215, 30, 500)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Load dataset\n",
    "\n",
    "# Define settings\n",
    "sensors_bodypart = 'all'\n",
    "sensors_type = ['Acc', 'Gyro']\n",
    "sensors_axis = 'all'\n",
    "standardize = False\n",
    "info_dataset = '1s_ssjjp' #1s_ssjjp means windows of 1 second, with classes shots, sprints, jumps, jogs and passes\n",
    "\n",
    "sensors_bodypart = '-'.join(sensors_bodypart) if isinstance(sensors_bodypart, list) else sensors_bodypart\n",
    "sensors_type = '-'.join(sensors_type) if isinstance(sensors_type, list) else sensors_type\n",
    "sensors_axis = '-'.join(sensors_axis) if isinstance(sensors_axis, list) else sensors_axis\n",
    "standardize = 'standardized' if standardize else 'unstandardized'\n",
    "\n",
    "# Path where the dataset is saved\n",
    "in_dir = r'/content/drive/MyDrive/Datasets_thesis/{}/{}_{}_{}_{}/'.format(info_dataset,\n",
    "                                                                         sensors_bodypart,\n",
    "                                                                         sensors_type,\n",
    "                                                                         sensors_axis,\n",
    "                                                                         standardize)\n",
    "\n",
    "# Load variables\n",
    "X_train = np.load(in_dir + 'X_train.npy')\n",
    "X_test = np.load(in_dir + 'X_test.npy')\n",
    "y_train = np.load(in_dir + 'y_train.npy')\n",
    "y_test = np.load(in_dir + 'y_test.npy')\n",
    "sensors = np.load(in_dir + 'sensors.npy')\n",
    "\n",
    "with open(in_dir + 'labels_dict.json') as json_file: \n",
    "    labels_dict = json.load(json_file) \n",
    "\n",
    "# Concatenate train and test dataset\n",
    "X = np.concatenate((X_train, X_test), axis = 0)\n",
    "y = np.concatenate((y_train, y_test), axis = 0)\n",
    "\n",
    "# Order of desired sensors\n",
    "\n",
    "order_sensors = ['leftShankAccX', 'leftShankAccY', 'leftShankAccZ',\n",
    "       'leftShankGyroX', 'leftShankGyroY', 'leftShankGyroZ',\n",
    "       'rightShankAccX', 'rightShankAccY', 'rightShankAccZ',\n",
    "       'rightShankGyroX', 'rightShankGyroY', 'rightShankGyroZ',\n",
    "       'leftThighAccX', 'leftThighAccY', 'leftThighAccZ',\n",
    "       'leftThighGyroX', 'leftThighGyroY', 'leftThighGyroZ',\n",
    "       'rightThighAccX', 'rightThighAccY', 'rightThighAccZ',\n",
    "       'rightThighGyroX', 'rightThighGyroY', 'rightThighGyroZ',\n",
    "       'pelvisAccX', 'pelvisAccY', 'pelvisAccZ', 'pelvisGyroX',\n",
    "       'pelvisGyroY', 'pelvisGyroZ']\n",
    "\n",
    "# Take only desired sensors in specified order\n",
    "ix_order_sensors = []\n",
    "for s in order_sensors:\n",
    "  if s in sensors:\n",
    "    ix_order_sensors.append(np.where(sensors == s)[0][0])\n",
    "X = X[:,ix_order_sensors,:]\n",
    "order_sensors = np.array(sensors)[ix_order_sensors]\n",
    "\n",
    "# Global normalization\n",
    "normalize = True\n",
    "\n",
    "# Whether to plot ans save confusion matrices\n",
    "confusion_matrix_plot = False\n",
    "\n",
    "print('Labels: {}\\n'.format(labels_dict))\n",
    "print('Order of sensors: {}\\n'.format(order_sensors))\n",
    "print('Size of dataset: {}'.format(X.shape))\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(labels_dict.keys(), y.sum(axis=0));\n",
    "plt.title('Train + test');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(X, y, model, classes,\n",
    "                          percentages=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          savefile=None):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `percentages=True`.\n",
    "    \"\"\"\n",
    "    predictions = model.predict(X)\n",
    "    cm = confusion_matrix(y.argmax(axis=1), predictions.argmax(axis=1)) \n",
    "\n",
    "    if percentages:\n",
    "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "      cm = cm * 100\n",
    "      print(\"\\nNormalized confusion matrix\")\n",
    "    else:\n",
    "      print('\\nConfusion matrix')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.1f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "      plt.text(j, i, format(cm[i, j], fmt) +'%',\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if savefile:\n",
    "        plt.savefig(savefile, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DX1ocMvIBAnq"
   },
   "outputs": [],
   "source": [
    "def split_per_sensor(x):\n",
    "    '''Splits x into parts of length 3 (each sensor has 3 axis)'''\n",
    "    return [x[:,i*3:(i+1)*3,:,:] for i in range(int(x.shape[1]/3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "id": "UQCJRXzJBCzk"
   },
   "outputs": [],
   "source": [
    "#@title 1DCNN weight sharing\n",
    "# 1DCNN weight_sharing\n",
    "def CNN_1D_ws(input_shape, classes):\n",
    "    \"\"\"\n",
    "    1DCNN weight sharing\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "\n",
    "    \"\"\"\n",
    "    ## Build model ##\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # CNN layer\n",
    "    X = Conv2D(16, (1,5), activation = 'relu')(X_input)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # CNN layer\n",
    "    X = Conv2D(32, (1,5), activation = 'relu')(X)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # CNN layer\n",
    "    X = Conv2D(64, (input_shape[0],1), activation = 'relu')(X)\n",
    "    \n",
    "    # Flatten \n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    # Dense Layer\n",
    "    X = Dense(64, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    ## Learning rate schedurer ##\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.001\n",
    "      drop = 0.75\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "\n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "id": "8c4skr_IBKi7"
   },
   "outputs": [],
   "source": [
    "#@title 1DCNN per sensor\n",
    "def CNN_1D_perSensor(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Split the input tensor per sensor\n",
    "    sensors = Lambda(split_per_sensor)(X_input)\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(16, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(32, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Concatenate the feature maps of all sensors\n",
    "    X = Concatenate(axis = 1)(sensors)\n",
    "    \n",
    "    # CNN layer\n",
    "    X = Conv2D(64, (input_shape[0],1), activation = 'relu')(X)\n",
    "    \n",
    "    # Flatten \n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    # Dense Layer\n",
    "    X = Dense(64, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.001\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "id": "BtOigboLBVHK"
   },
   "outputs": [],
   "source": [
    "#@title 1DCNN combined\n",
    "def CNN_1D_combined(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Create model\n",
    "\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Split the input tensor per sensor\n",
    "    sensors = Lambda(split_per_sensor)(X_input)\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(16, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(32, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(16, (1,5), activation = 'relu')(X_input)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(32, (1,5), activation = 'relu')(X)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "\n",
    "    # Concatenate the feature maps of all sensors and weight sharing part\n",
    "    sensors.append(X)\n",
    "    X = Concatenate(axis = 1)(sensors)\n",
    "    \n",
    "    # CNN layer\n",
    "    X = Conv2D(64, (input_shape[0]*2,1), activation = 'relu')(X)\n",
    "    \n",
    "    # Flatten \n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    # Dense Layer\n",
    "    X = Dense(64, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define mode\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "      \n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "        initial_lrate = 0.001\n",
    "        drop = 0.75 # Keep percentage\n",
    "        epochs_drop = 10\n",
    "        lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "        return lrate\n",
    "\n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "id": "1WaiZcxqGast"
   },
   "outputs": [],
   "source": [
    "#@title 2DCNN weight sharing\n",
    "def CNN_2D_ws(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Create model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(16, (3,5), strides = (3,1), activation = 'relu')(X_input)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(32, (1,5), activation = 'relu')(X)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # CNN layer\n",
    "    X = Conv2D(16, (int(input_shape[0]/3),1), activation = 'relu')(X)\n",
    "    \n",
    "    # Flatten \n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    # Dense Layer\n",
    "    X = Dense(64, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.001\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "\n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "cUi87F6tG8Us"
   },
   "outputs": [],
   "source": [
    "#@title 2DCNN per sensor\n",
    "def CNN_2D_perSensor(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Create model\n",
    "    #Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Split the input tensor per sensor\n",
    "    sensors = Lambda(split_per_sensor)(X_input)\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(16, (3,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(16, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Concatenate the feature maps of all sensors\n",
    "    X = Concatenate(axis = 1)(sensors)\n",
    "    \n",
    "    # CNN layer\n",
    "    X = Conv2D(32, (int(input_shape[0]/3),1), activation = 'relu')(X)\n",
    "    \n",
    "    # Flatten \n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    # Dense Layer\n",
    "    X = Dense(64, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.001\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "\n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "form",
    "id": "S99tHSsLHctk"
   },
   "outputs": [],
   "source": [
    "#@title 2DCNN all signals\n",
    "def CNN_2D_allSignals(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Create model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(32, (input_shape[0],5), activation = 'relu')(X_input)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(32, (1,5), activation = 'relu')(X)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # Flatten \n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    # Dense Layer\n",
    "    X = Dense(64, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.001\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "form",
    "id": "aFCZchZoIAL7"
   },
   "outputs": [],
   "source": [
    "#@title 2DCNN combined\n",
    "def CNN_2D_combined(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Create model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Split the input tensor per sensor\n",
    "    sensors = Lambda(split_per_sensor)(X_input)\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(16, (3,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(32, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    normal = Conv2D(16, (3,5), strides = (3,1), activation = 'relu')(X_input)\n",
    "    normal = MaxPooling2D((1,4))(normal)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    normal = Conv2D(32, (1,5), activation = 'relu')(normal)\n",
    "    normal = MaxPooling2D((1,4))(normal)\n",
    "    \n",
    "    \n",
    "    # CNN layer with weight sharing all signals\n",
    "    all_signals = Conv2D(32, (input_shape[0],5), activation = 'relu')(X_input)\n",
    "    all_signals = MaxPooling2D((1,4))(all_signals)\n",
    "    \n",
    "    # CNN layer with weight sharing all signals\n",
    "    all_signals = Conv2D(32, (1,5), activation = 'relu')(all_signals)\n",
    "    all_signals = MaxPooling2D((1,4))(all_signals)\n",
    "    \n",
    "    # Concatenate all feature maps\n",
    "    sensors.append(normal)\n",
    "    sensors.append(all_signals)\n",
    "    X = Concatenate(axis = 1)(sensors)\n",
    "    \n",
    "    # CNN layer\n",
    "    X = Conv2D(64, (int(1+2*input_shape[0]/3),1), activation = 'relu')(X)\n",
    "    \n",
    "    # Flatten \n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    # Dense Layer\n",
    "    X = Dense(64, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.001\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "form",
    "id": "flKAUTCQIZQv"
   },
   "outputs": [],
   "source": [
    "#@title 1DCNN weight sharing LSTM\n",
    "def CNN_1D_ws_LSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Create model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # CNN layer\n",
    "    X = Conv2D(16, (1,5), activation = 'relu')(X_input)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # CNN layer\n",
    "    X = Conv2D(32, (1,5), activation = 'relu')(X)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "\n",
    "    # CNN layer to prepare for LSTM\n",
    "    last_kernels = 128\n",
    "    X = Conv2D(last_kernels, (input_shape[0],1), activation = 'relu')(X)\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "\n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "form",
    "id": "XTiRYpjAZLtM"
   },
   "outputs": [],
   "source": [
    "#@title 1DCNN per sensor LSTM\n",
    "def CNN_1D_perSensor_LSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Split the input tensor per sensor\n",
    "    sensors = Lambda(split_per_sensor)(X_input)\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(16, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(32, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Concatenate the feature maps of all sensors\n",
    "    X = Concatenate(axis = 1)(sensors)\n",
    "\n",
    "    # CNN layer to prepare for LSTM\n",
    "    last_kernels = 128\n",
    "    X = Conv2D(last_kernels, (input_shape[0],1), activation = 'relu')(X)\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellView": "form",
    "id": "JwNBIZAKbcmg"
   },
   "outputs": [],
   "source": [
    "#@title 1DCNN combined LSTM\n",
    "def CNN_1D_combined_LSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Split the input tensor per sensor\n",
    "    sensors = Lambda(split_per_sensor)(X_input)\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(16, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(32, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(16, (1,5), activation = 'relu')(X_input)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(32, (1,5), activation = 'relu')(X)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # Concatenate the feature maps of all sensors\n",
    "    sensors.append(X)\n",
    "    X = Concatenate(axis = 1)(sensors)\n",
    "\n",
    "    # CNN layer to prepare for LSTM\n",
    "    last_kernels = 128\n",
    "    X = Conv2D(last_kernels, (input_shape[0]*2,1), activation = 'relu')(X)\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "form",
    "id": "oc7ZVjT0eZ5z"
   },
   "outputs": [],
   "source": [
    "#@title 2DCNN weight sharing LSTM\n",
    "def CNN_2D_ws_LSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(32, (3,5), strides = (3,1), activation = 'relu')(X_input)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(64, (1,5), activation = 'relu')(X)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "\n",
    "    # CNN layer to prepare for LSTM\n",
    "    last_kernels = 128\n",
    "    X = Conv2D(last_kernels, (int(input_shape[0]/3),1), activation = 'relu')(X)\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "form",
    "id": "h2R5LVn8d1rl"
   },
   "outputs": [],
   "source": [
    "#@title 2DCNN per sensor LSTM\n",
    "def CNN_2D_perSensor_LSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Split the input tensor per sensor\n",
    "    sensors = Lambda(split_per_sensor)(X_input)\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(32, (3,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(64, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Concatenate the feature maps of all sensors\n",
    "    X = Concatenate(axis = 1)(sensors)\n",
    "\n",
    "    # CNN layer to prepare for LSTM\n",
    "    last_kernels = 128\n",
    "    X = Conv2D(last_kernels, (int(input_shape[0]/3),1), activation = 'relu')(X)\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "\n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellView": "form",
    "id": "CTx_y2cFgk5k"
   },
   "outputs": [],
   "source": [
    "#@title 2DCNN all signals LSTM\n",
    "def CNN_2D_allSignals_LSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "\n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(32, (input_shape[0],5), activation = 'relu')(X_input)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "\n",
    "    last_kernels = 64\n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(last_kernels, (1,5), activation = 'relu')(X)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "\n",
    "    # Format tensor for LSTM\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellView": "form",
    "id": "sJhMAochhSVT"
   },
   "outputs": [],
   "source": [
    "#@title 2DCNN combined LSTM\n",
    "def CNN_2D_combined_LSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "\n",
    "    # Split the input tensor per sensor\n",
    "    sensors = Lambda(split_per_sensor)(X_input)\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(32, (3,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(64, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    normal = Conv2D(32, (3,5), strides = (3,1), activation = 'relu')(X_input)\n",
    "    normal = MaxPooling2D((1,4))(normal)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    normal = Conv2D(64, (1,5), activation = 'relu')(normal)\n",
    "    normal = MaxPooling2D((1,4))(normal)\n",
    "    \n",
    "    \n",
    "    # CNN layer with weight sharing all signals\n",
    "    all_signals = Conv2D(32, (input_shape[0],5), activation = 'relu')(X_input)\n",
    "    all_signals = MaxPooling2D((1,4))(all_signals)\n",
    "    \n",
    "    # CNN layer with weight sharing all signals\n",
    "    all_signals = Conv2D(64, (1,5), activation = 'relu')(all_signals)\n",
    "    all_signals = MaxPooling2D((1,4))(all_signals)\n",
    "    \n",
    "\n",
    "    # Concatenate all feature maps\n",
    "    sensors.append(normal)\n",
    "    sensors.append(all_signals)\n",
    "    X = Concatenate(axis = 1)(sensors)\n",
    "    \n",
    "    # CNN layer to prepare for LSTM\n",
    "    last_kernels = 128\n",
    "    X = Conv2D(last_kernels, (int(1+2*input_shape[0]/3),1), activation = 'relu')(X)\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "form",
    "id": "mfQXOM8phyBX"
   },
   "outputs": [],
   "source": [
    "#@title 1DCNN weight sharing bLSTM\n",
    "def CNN_1D_ws_bLSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Create model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # CNN layer\n",
    "    X = Conv2D(16, (1,5), activation = 'relu')(X_input)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # CNN layer\n",
    "    X = Conv2D(32, (1,5), activation = 'relu')(X)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "\n",
    "    # CNN layer to prepare for LSTM\n",
    "    last_kernels = 128\n",
    "    X = Conv2D(last_kernels, (input_shape[0],1), activation = 'relu')(X)\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=True))(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=False))(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "\n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellView": "form",
    "id": "3gpVSLcPiHQE"
   },
   "outputs": [],
   "source": [
    "#@title 1DCNN per sensor bLSTM\n",
    "def CNN_1D_perSensor_bLSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Split the input tensor per sensor\n",
    "    sensors = Lambda(split_per_sensor)(X_input)\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(16, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(32, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Concatenate the feature maps of all sensors\n",
    "    X = Concatenate(axis = 1)(sensors)\n",
    "\n",
    "    # CNN layer to prepare for LSTM\n",
    "    last_kernels = 128\n",
    "    X = Conv2D(last_kernels, (input_shape[0],1), activation = 'relu')(X)\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=True))(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=False))(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellView": "form",
    "id": "dOwnks4GiPgO"
   },
   "outputs": [],
   "source": [
    "#@title 1DCNN combined bLSTM\n",
    "def CNN_1D_combined_bLSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Split the input tensor per sensor\n",
    "    sensors = Lambda(split_per_sensor)(X_input)\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(16, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(32, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(16, (1,5), activation = 'relu')(X_input)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(32, (1,5), activation = 'relu')(X)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # Concatenate the feature maps of all sensors\n",
    "    sensors.append(X)\n",
    "    X = Concatenate(axis = 1)(sensors)\n",
    "\n",
    "    # CNN layer to prepare for LSTM\n",
    "    last_kernels = 128\n",
    "    X = Conv2D(last_kernels, (input_shape[0]*2,1), activation = 'relu')(X)\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=True))(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=False))(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellView": "form",
    "id": "bfMfuxB4iX8Q"
   },
   "outputs": [],
   "source": [
    "#@title 2DCNN weight sharing bLSTM\n",
    "def CNN_2D_ws_bLSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(32, (3,5), strides = (3,1), activation = 'relu')(X_input)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(64, (1,5), activation = 'relu')(X)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "\n",
    "    # CNN layer to prepare for LSTM\n",
    "    last_kernels = 128\n",
    "    X = Conv2D(last_kernels, (int(input_shape[0]/3),1), activation = 'relu')(X)\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=True))(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=False))(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellView": "form",
    "id": "krdKd2rlihGd"
   },
   "outputs": [],
   "source": [
    "#@title 2DCNN per sensor bLSTM\n",
    "def CNN_2D_perSensor_bLSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Split the input tensor per sensor\n",
    "    sensors = Lambda(split_per_sensor)(X_input)\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(32, (3,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(64, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Concatenate the feature maps of all sensors\n",
    "    X = Concatenate(axis = 1)(sensors)\n",
    "\n",
    "    # CNN layer to prepare for LSTM\n",
    "    last_kernels = 128\n",
    "    X = Conv2D(last_kernels, (int(input_shape[0]/3),1), activation = 'relu')(X)\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=True))(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=False))(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "\n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cellView": "form",
    "id": "aGy8pMr24Zb2"
   },
   "outputs": [],
   "source": [
    "#@title 2DCNN all signals bLSTM\n",
    "def CNN_2D_allSignals_bLSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "\n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(32, (input_shape[0],5), activation = 'relu')(X_input)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "\n",
    "    last_kernels = 64\n",
    "    # CNN layer with weight sharing\n",
    "    X = Conv2D(last_kernels, (1,5), activation = 'relu')(X)\n",
    "    X = MaxPooling2D((1,4))(X)\n",
    "\n",
    "    # Format tensor for LSTM\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=True))(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=False))(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellView": "form",
    "id": "3Hwdkhl34ihr"
   },
   "outputs": [],
   "source": [
    "#@title 2DCNN combined bLSTM\n",
    "def CNN_2D_combined_bLSTM(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "\n",
    "    # Split the input tensor per sensor\n",
    "    sensors = Lambda(split_per_sensor)(X_input)\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(32, (3,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    # Independent CNN per sensor\n",
    "    sensors = [Conv2D(64, (1,5), activation = 'relu')(sensor) for sensor in sensors]\n",
    "    sensors = [MaxPooling2D((1,4))(sensor) for sensor in sensors]\n",
    "    \n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    normal = Conv2D(32, (3,5), strides = (3,1), activation = 'relu')(X_input)\n",
    "    normal = MaxPooling2D((1,4))(normal)\n",
    "    \n",
    "    # CNN layer with weight sharing\n",
    "    normal = Conv2D(64, (1,5), activation = 'relu')(normal)\n",
    "    normal = MaxPooling2D((1,4))(normal)\n",
    "    \n",
    "    \n",
    "    # CNN layer with weight sharing all signals\n",
    "    all_signals = Conv2D(32, (input_shape[0],5), activation = 'relu')(X_input)\n",
    "    all_signals = MaxPooling2D((1,4))(all_signals)\n",
    "    \n",
    "    # CNN layer with weight sharing all signals\n",
    "    all_signals = Conv2D(64, (1,5), activation = 'relu')(all_signals)\n",
    "    all_signals = MaxPooling2D((1,4))(all_signals)\n",
    "    \n",
    "\n",
    "    # Concatenate all feature maps\n",
    "    sensors.append(normal)\n",
    "    sensors.append(all_signals)\n",
    "    X = Concatenate(axis = 1)(sensors)\n",
    "    \n",
    "    # CNN layer to prepare for LSTM\n",
    "    last_kernels = 128\n",
    "    X = Conv2D(last_kernels, (int(1+2*input_shape[0]/3),1), activation = 'relu')(X)\n",
    "    X = Permute((2, 1, 3))(X)\n",
    "    X = Reshape((-1, last_kernels))(X)\n",
    "\n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=True))(X)\n",
    "  \n",
    "    # LSTM layer\n",
    "    X = Bidirectional(LSTM(128, return_sequences=False))(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # Dense Layer\n",
    "    X = Dense(128, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.0005\n",
    "      drop = 0.75 # Keep percentage\n",
    "      epochs_drop = 10\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "    \n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellView": "form",
    "id": "c5nf-tHY4s2x"
   },
   "outputs": [],
   "source": [
    "#@title LSTM\n",
    "def lstm(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # LSTM\n",
    "    X = LSTM(128, return_sequences=True)(X_input)\n",
    "    \n",
    "    # LSTM\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    # Dense Layer\n",
    "    X = Dense(64, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(64, activation = 'relu')(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "\n",
    "    ## Learning rate scheduler \n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.001\n",
    "      drop = 0.50 # Keep percentage\n",
    "      epochs_drop = 20\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "\n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellView": "form",
    "id": "863rMxxo5TLm"
   },
   "outputs": [],
   "source": [
    "#@title bLSTM\n",
    "def blstm(input_shape, classes):\n",
    "    \"\"\"\n",
    "    Creates a keras model\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    classes -- number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    ## Build model\n",
    "    # Input\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # bLSTM\n",
    "    X = Bidirectional(LSTM(128, return_sequences=True))(X_input)\n",
    "    \n",
    "    # bLSTM\n",
    "    X = Bidirectional(LSTM(128, return_sequences=False))(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    # Dense Layer\n",
    "    X = Dense(64, activation = 'relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(64, activation = 'relu')(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "    \n",
    "    # Output\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Define model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "\n",
    "    ## Learning rate scheduler\n",
    "    def lr_step_decay(epoch):\n",
    "      initial_lrate = 0.001\n",
    "      drop = 0.50 # Keep percentage\n",
    "      epochs_drop = 20\n",
    "      lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "      return lrate\n",
    "\n",
    "    return model, lr_step_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xF_KHWDN5ntz"
   },
   "outputs": [],
   "source": [
    "# Name of the models that contain CNN part\n",
    "model_function_names_CNN = {'1DCNN_ws': 'CNN_1D_ws',\n",
    "                            '1DCNN_perSensor': 'CNN_1D_perSensor', \n",
    "                            '1DCNN_combined': 'CNN_1D_combined',\n",
    "                            '2DCNN_ws': 'CNN_2D_ws',\n",
    "                            '2DCNN_perSensor': 'CNN_2D_perSensor',\n",
    "                            '2DCNN_allSignals': 'CNN_2D_allSignals',\n",
    "                            '2DCNN_combined': 'CNN_2D_combined',\n",
    "                            '1DCNN_ws_LSTM': 'CNN_1D_ws_LSTM',\n",
    "                            '1DCNN_perSensor_LSTM': 'CNN_1D_perSensor_LSTM',\n",
    "                            '1DCNN_combined_LSTM': 'CNN_1D_combined_LSTM',\n",
    "                            '2DCNN_ws_LSTM': 'CNN_2D_ws_LSTM',\n",
    "                            '2DCNN_perSensor_LSTM': 'CNN_2D_perSensor_LSTM',\n",
    "                            '2DCNN_allSignals_LSTM': 'CNN_2D_allSignals_LSTM',\n",
    "                            '2DCNN_combined_LSTM':'CNN_2D_combined_LSTM',\n",
    "                            '1DCNN_ws_bLSTM': 'CNN_1D_ws_bLSTM',\n",
    "                            '1DCNN_perSensor_bLSTM': 'CNN_1D_perSensor_bLSTM',\n",
    "                            '1DCNN_combined_bLSTM': 'CNN_1D_combined_bLSTM',\n",
    "                            '2DCNN_ws_bLSTM': 'CNN_2D_ws_bLSTM',\n",
    "                            '2DCNN_perSensor_bLSTM': 'CNN_2D_perSensor_bLSTM',\n",
    "                            '2DCNN_allSignals_bLSTM': 'CNN_2D_allSignals_bLSTM',\n",
    "                            '2DCNN_combined_bLSTM': 'CNN_2D_combined_bLSTM'}\n",
    "\n",
    "# Name of the models that do not contain CNN part\n",
    "model_function_names_RNN = {'LSTM': 'lstm', \n",
    "                            'bLSTM': 'blstm'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2TL9Wgy6Lie"
   },
   "outputs": [],
   "source": [
    "def createModel(name_model, X, y):\n",
    "  '''\n",
    "  Create model.\n",
    "  Returns the model and the learning rate scheduler\n",
    "  '''\n",
    "  tf.compat.v1.reset_default_graph()\n",
    "  tf.keras.backend.clear_session()\n",
    "  _ = gc.collect()\n",
    "\n",
    "  # Models with CNN \n",
    "  if name_model in model_function_names_CNN: \n",
    "    model, lr = eval(model_function_names_CNN[name_model])((X.shape[1], X.shape[2], 1), y.shape[1])\n",
    "  # Models without CNN. Their input is slightly different\n",
    "  else:\n",
    "    model, lr = eval(model_function_names_RNN[name_model])((X.shape[1], X.shape[2]), y.shape[1])\n",
    "\n",
    "  return model, lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCvzLI_M_rbK"
   },
   "outputs": [],
   "source": [
    "def trainModels(X, y, model_function_names_CNN, model_function_names_RNN, epochs = 200, normalize = True, confusion_matrix_plot = False):\n",
    "  '''Train all the models and get loss and accuracy for train and test datasets'''\n",
    "\n",
    "  # Define optimizer\n",
    "  opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "  metrics = {}\n",
    "\n",
    "  # Train test split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "  if normalize:\n",
    "    # Normalize X_train sensors to have max absolute value equal to 1\n",
    "    max_train = np.max(np.max(X_train, axis = 0), axis = -1)\n",
    "    min_train = np.min(np.min(X_train, axis = 0), axis = -1)\n",
    "    abs_train = np.max([np.abs(min_train), np.abs(max_train)], axis = 0)\n",
    "    X_train = X_train/abs_train[:,None]\n",
    "\n",
    "    # Normalize X_test sensors to have max absolute value equal to 1\n",
    "    max_test = np.max(np.max(X_test, axis = 0), axis = -1)\n",
    "    min_test = np.min(np.min(X_test, axis = 0), axis = -1)\n",
    "    abs_test = np.max([np.abs(min_test), np.abs(max_test)], axis = 0)\n",
    "    X_test = X_test/abs_test[:,None]\n",
    "\n",
    "  ###### Models with CNN part ######\n",
    "  # Adds dimension to Xtrain and Xtest (CNN models require this additional dim)\n",
    "  X_train_CNN = tf.convert_to_tensor(np.expand_dims(X_train, axis = 3), dtype = tf.float32)\n",
    "  X_test_CNN = tf.convert_to_tensor(np.expand_dims(X_test, axis = 3), dtype = tf.float32)\n",
    "\n",
    "  for name_model in model_function_names_CNN:\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    print('Training model {}...'.format(name_model))\n",
    "    model, lr = createModel(name_model, X_train_CNN, y_train) \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "    model.fit(X_train_CNN, \n",
    "              y_train,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_test_CNN, y_test),\n",
    "              verbose = 0,\n",
    "              batch_size = 32,\n",
    "              callbacks = [EarlyStopping(patience = 10, restore_best_weights = True, monitor = 'val_loss'),\n",
    "                            LearningRateScheduler(lr, verbose=0)]\n",
    "              )\n",
    "    \n",
    "    # Get accuracy and loss of train dataset\n",
    "    metrics[name_model] = {}\n",
    "    train_metrics = model.evaluate(X_train_CNN, y_train, return_dict = True)\n",
    "    metrics[name_model]['loss'] = [train_metrics['loss']]\n",
    "    metrics[name_model]['accuracy'] = [train_metrics['accuracy']]\n",
    "\n",
    "    # Get accuracy and loss of test dataset  \n",
    "    test_metrics = model.evaluate(X_test_CNN, y_test, return_dict = True)\n",
    "    metrics[name_model]['test_loss'] = [test_metrics['loss']]\n",
    "    metrics[name_model]['test_accuracy'] = [test_metrics['accuracy']]\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    if confusion_matrix_plot:\n",
    "        plot_confusion_matrix(X_test_CNN, y_test, model,\n",
    "                          classes=labels_dict.keys(),\n",
    "                          title='Confusion matrix model {}'.format(name_model),\n",
    "                          savefile = 'confusion_matrix_{}.png'.format(name_model))\n",
    "\n",
    "    # Release memory\n",
    "    del model\n",
    "    del lr\n",
    "    gc.collect()\n",
    "\n",
    "  ###### Models without CNN part ######\n",
    "  # Reshapes X matrices into (samples, timesteps, features) (Only RNN models require this)\n",
    "  X_train_RNN = tf.convert_to_tensor(np.transpose(X_train, (0, 2, 1)), dtype = tf.float32)\n",
    "  X_test_RNN = tf.convert_to_tensor(np.transpose(X_test, (0, 2, 1)), dtype = tf.float32)\n",
    "\n",
    "  for name_model in model_function_names_RNN: \n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    print('Training model {}...'.format(name_model))\n",
    "    model, lr = createModel(name_model, X_train_RNN, y_train) \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "    model.fit(X_train_RNN, \n",
    "              y_train,\n",
    "              epochs=epochs,\n",
    "              validation_data=(X_test_RNN, y_test),\n",
    "              verbose = 0,\n",
    "              batch_size = 32,\n",
    "              callbacks = [EarlyStopping(patience = 10, restore_best_weights = True, monitor = 'val_loss'),\n",
    "                            LearningRateScheduler(lr, verbose=0)]\n",
    "              )\n",
    "    \n",
    "    # Get accuracy and loss of train dataset\n",
    "    metrics[name_model] = {}\n",
    "    train_metrics = model.evaluate(X_train_RNN, y_train, return_dict = True)\n",
    "    metrics[name_model]['loss'] = [train_metrics['loss']]\n",
    "    metrics[name_model]['accuracy'] = [train_metrics['accuracy']]\n",
    "\n",
    "    # Get accuracy and loss of test dataset  \n",
    "    test_metrics = model.evaluate(X_test_RNN, y_test, return_dict = True)\n",
    "    metrics[name_model]['test_loss'] = [test_metrics['loss']]\n",
    "    metrics[name_model]['test_accuracy'] = [test_metrics['accuracy']]\n",
    "  \n",
    "    # Plot confusion matrix\n",
    "    if confusion_matrix_plot:\n",
    "        plot_confusion_matrix(X_test_RNN, y_test, model,\n",
    "                          classes=labels_dict.keys(),\n",
    "                          title='Confusion matrix model {}'.format(name_model),\n",
    "                          savefile = 'confusion_matrix_{}.png'.format(name_model))\n",
    "    \n",
    "    # Delete previous model to save memory\n",
    "    del model\n",
    "    del lr\n",
    "    gc.collect()\n",
    "\n",
    "  tf.compat.v1.reset_default_graph()\n",
    "  tf.keras.backend.clear_session()\n",
    "  \n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JW07D6xCA3op"
   },
   "outputs": [],
   "source": [
    "def train_repetitions(X, y, model_function_names_CNN, model_function_names_RNN, num_trainings = 1, epochs = 200, normalize = True, confusion_matrix_plot = False):\n",
    "  '''Train the models num_repetitions times and return their metrics'''\n",
    "\n",
    "  for i in range(num_trainings):\n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('Repetition {}/{}'.format(i+1, num_trainings))\n",
    "\n",
    "    if i == 0:\n",
    "      # Initialize metrics with first ones\n",
    "      metrics = trainModels(X, y, model_function_names_CNN, model_function_names_RNN, epochs, normalize, confusion_matrix_plot)\n",
    "    else:\n",
    "      temp_metrics = trainModels(X, y, model_function_names_CNN, model_function_names_RNN, epochs, normalize, confusion_matrix_plot)\n",
    "      # Append metrics\n",
    "      for name_model in metrics:\n",
    "        for metric in metrics[name_model]:\n",
    "          metrics[name_model][metric].extend(temp_metrics[name_model][metric])\n",
    "          \n",
    "  tf.keras.backend.clear_session()\n",
    "  tf.compat.v1.reset_default_graph()\n",
    "  print('DONE')\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZV5G4kBF-vp",
    "outputId": "41ea6b6d-1b2f-42cf-ec72-7623259b14e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "Repetition 1/1\n",
      "Training model 1DCNN_ws...\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9718\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2080 - accuracy: 0.9425\n",
      "Training model 1DCNN_perSensor...\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0566 - accuracy: 0.9812\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1920 - accuracy: 0.9425\n",
      "Training model 1DCNN_combined...\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0472 - accuracy: 0.9882\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1735 - accuracy: 0.9397\n",
      "Training model 2DCNN_ws...\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.9588\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2034 - accuracy: 0.9507\n",
      "Training model 2DCNN_perSensor...\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0921 - accuracy: 0.9682\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.1910 - accuracy: 0.9342\n",
      "Training model 2DCNN_allSignals...\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9812\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9425\n",
      "Training model 2DCNN_combined...\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0567 - accuracy: 0.9765\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.1534 - accuracy: 0.9589\n",
      "Training model 1DCNN_ws_LSTM...\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.1074 - accuracy: 0.9635\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1495 - accuracy: 0.9479\n",
      "Training model 1DCNN_perSensor_LSTM...\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.1541 - accuracy: 0.9447\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1650 - accuracy: 0.9616\n",
      "Training model 1DCNN_combined_LSTM...\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.1825 - accuracy: 0.9376\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1580 - accuracy: 0.9534\n",
      "Training model 2DCNN_ws_LSTM...\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.1360 - accuracy: 0.9471\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1229 - accuracy: 0.9534\n",
      "Training model 2DCNN_perSensor_LSTM...\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.2543 - accuracy: 0.9176\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2438 - accuracy: 0.9233\n",
      "Training model 2DCNN_allSignals_LSTM...\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.1609 - accuracy: 0.9435\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1935 - accuracy: 0.9342\n",
      "Training model 2DCNN_combined_LSTM...\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.1147 - accuracy: 0.9553\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1249 - accuracy: 0.9589\n",
      "Training model 1DCNN_ws_bLSTM...\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0900 - accuracy: 0.9659\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1166 - accuracy: 0.9699\n",
      "Training model 1DCNN_perSensor_bLSTM...\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.1279 - accuracy: 0.9553\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1910 - accuracy: 0.9452\n",
      "Training model 1DCNN_combined_bLSTM...\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.1005 - accuracy: 0.9553\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.1436 - accuracy: 0.9589\n",
      "Training model 2DCNN_ws_bLSTM...\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 0.0803 - accuracy: 0.9659\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1702 - accuracy: 0.9452\n",
      "Training model 2DCNN_perSensor_bLSTM...\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0914 - accuracy: 0.9682\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1733 - accuracy: 0.9616\n",
      "Training model 2DCNN_allSignals_bLSTM...\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 0.0405 - accuracy: 0.9859\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1658 - accuracy: 0.9534\n",
      "Training model 2DCNN_combined_bLSTM...\n",
      "27/27 [==============================] - 0s 17ms/step - loss: 0.0659 - accuracy: 0.9753\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1704 - accuracy: 0.9425\n",
      "Training model LSTM...\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 0.9949 - accuracy: 0.6200\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 1.0704 - accuracy: 0.5753\n",
      "Training model bLSTM...\n",
      "27/27 [==============================] - 4s 134ms/step - loss: 0.3620 - accuracy: 0.8871\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.4596 - accuracy: 0.8411\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "metrics = train_repetitions(X, y, model_function_names_CNN, model_function_names_RNN, num_trainings = 1, epochs = 200, normalize = normalize, confusion_matrix_plot = confusion_matrix_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsWtd3flGkhE",
    "outputId": "f72781fe-d493-49ec-b830-09f97f48a081"
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcNSTcKzL1c7"
   },
   "outputs": [],
   "source": [
    "with open('metrics.json', 'w') as fp:\n",
    "    json.dump(metrics, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yGr-ITjNeWM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "All_models normalized",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
